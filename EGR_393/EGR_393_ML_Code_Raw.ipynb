{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EGR_393_ML_Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JbzDwB8T4aJ",
        "colab_type": "text"
      },
      "source": [
        "*Import the needed tensorflow and python libraries needed for data modification*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhP5j5K4STyn",
        "colab_type": "code",
        "outputId": "4e16c21d-e165-425b-aee2-0e44b6aca820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "#!pip install tensorflow==1.14.0rc1\n",
        "\n",
        "#!pip install keras==2.2.4\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import PIL\n",
        "import imageio\n",
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage import transform\n",
        "from skimage import draw\n",
        "from skimage import exposure\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import requests\n",
        "import tarfile\n",
        "import dlib\n",
        "import sys\n",
        "from PIL import Image\n",
        "from PIL.ExifTags import TAGS\n",
        "!pip install -q tf-nightly\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tarfile\n",
        "import keras\n",
        "import errno\n",
        "import urllib\n",
        "try:\n",
        "    from imageio import imsave\n",
        "except:\n",
        "    from scipy.misc import imsave\n",
        "\n",
        "  \n",
        "import sys\n",
        "import urllib.request\n",
        "from urllib.request import urlretrieve\n",
        "from csv import reader\n",
        "import os.path\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from skimage import io\n",
        "import matplotlib.image as mpimg\n",
        "from scipy import ndimage, misc\n",
        "import h5py\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as _Imgdis\n",
        "from PIL import Image\n",
        "from scipy import ndimage"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4tS-mR0T6nF",
        "colab_type": "text"
      },
      "source": [
        "*Import the Google Drive Authorization needed to access the data folders*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZE3I515SfA7",
        "colab_type": "code",
        "outputId": "995435d5-c7ef-4939-cc6a-6200e8fdba71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxzQM9_nT--Q",
        "colab_type": "text"
      },
      "source": [
        "*Move into My Drive, where my image folders are stored*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0R5EGMoSj3V",
        "colab_type": "code",
        "outputId": "5f23f822-5f5b-4c39-e0be-76c696bca55a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/gdrive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d9MQH_TUBXb",
        "colab_type": "text"
      },
      "source": [
        "*Create the paths to the directories of the images, which are stored in their own folders in My Drive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJLHF3qmSll-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deer_train_path= '/content/gdrive/My Drive/Deer/deer_train'\n",
        "notDeer_train_path = '/content/gdrive/My Drive/Deer/notDeer_train/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-qv_XT_UFpP",
        "colab_type": "text"
      },
      "source": [
        "@param: path_in - *The path to the folder of images*\n",
        "@param: arrayName *An array to store the images*\n",
        "\n",
        "Every file (or image) in the folder is read in RGB format, as BGR is the default for openCV\n",
        "\n",
        "The image is the resized to (224,224), which is the height and width ised by most pre-trained models\n",
        "\n",
        "The image is then appended to an array\n",
        "\n",
        "The if statement is included because one of the images in the not deer training folder, at index 465, was not working and this bypassed that image \n",
        "\n",
        "@return: ArrayName *The same images now populated with image data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Joa0eoSmEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imageAdder(path_in, arrayName):\n",
        "   \n",
        "    path = path_in\n",
        "    i=0\n",
        "    for image_path in os.listdir(path):\n",
        "            input_path = os.path.join(path, image_path)\n",
        "            image = cv2.imread(input_path)\n",
        "            image2 =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            #image = (image/127.5) - 1\n",
        "            img = cv2.resize(image2,(224,224)) #crop rather than resize -keeps aspect ratio\n",
        "            arrayName.append(img)\n",
        "            print(image_path)\n",
        "            i = i+1\n",
        "    return arrayName"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DnXpCH0UI9G",
        "colab_type": "text"
      },
      "source": [
        "*Instantiating the arrays that will hold the training and testing images for deer and not deer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4i_s7r2SpAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deer_train = []\n",
        "nDeer_train =[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvi9ojQ7ULqF",
        "colab_type": "text"
      },
      "source": [
        "*Populating the previously instantiated arrays with image data from the folders*\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zSoQvxySrWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deer_train = imageAdder(deer_train_path, deer_train)\n",
        "\n",
        "nDeer_train = imageAdder(notDeer_train_path, nDeer_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGnQ1JaiUN26",
        "colab_type": "text"
      },
      "source": [
        "*Converting the arrays from lists to NumPy arrays, which allows for multi-dimensionality and is how the data will be fed into the model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11pd29UASteO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deer_train = np.asarray(deer_train)\n",
        "nDeer_train =np.asarray(nDeer_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SEREt8UUhBW",
        "colab_type": "text"
      },
      "source": [
        "*Seeing the shape of the arrays holding the data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxI0d1pGSxen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(deer_train.shape) \n",
        "print(nDeer_train.shape)\n",
        "plt.imshow(deer_train[578])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fISV2wrdUlVd",
        "colab_type": "text"
      },
      "source": [
        "*Creating the label arrays for the images. Assigning 1 to indicate a deer and 0 to indicate a not deer. Using np.ones or np.zeros created a numpy array of 1's or 0's, which have their length determined by the length of the corresponding image arrays. The prints after the assignments are used to test whether the labels were generated correctly.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30wH5zeoS5t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLabelsDeer = np.ones(len(deer_train))\n",
        "print(len(trainLabelsDeer))\n",
        "\n",
        "trainLabelsNotDeer = np.zeros(len(nDeer_train))\n",
        "print(len(trainLabelsNotDeer))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdChXfWtUn6L",
        "colab_type": "text"
      },
      "source": [
        "*This adds the training labels together and the testing labels together in one array. The arrays are in order, so the first half are deer images and the second half are not deer images.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aKopFHZS7gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_total = np.concatenate((deer_train,nDeer_train))\n",
        "y_total = np.concatenate((trainLabelsDeer, trainLabelsNotDeer))\n",
        "y_total = keras.utils.np_utils.to_categorical(y_total)\n",
        "y_total = y_total.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3D4UhC0Uqii",
        "colab_type": "text"
      },
      "source": [
        "*Printing the length of the training images, testing images, training labels and testing labels arrays to make sure the addition was successful*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRcK1Lx9S92n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(x_total))\n",
        "y_total = y_total.astype(int)\n",
        "print(y_total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljw861ZSUt7r",
        "colab_type": "text"
      },
      "source": [
        "*Printing the shape to make sure the images were all standardized (224x224x3) and that the number of samples is the number added as well*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBoC8Oh1S_1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_total, y_total,test_size=0.2)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaBu0LOkUwtJ",
        "colab_type": "text"
      },
      "source": [
        "* **Commented Out**\n",
        "* *Turning the labels into categories rather than just numbers. Use when using binary or categorical cross-entropy, not sparse categorical cross-entropy*\n",
        "* However, I found that it is more accurate with sparse categorical cross-entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4tGH-eCTCQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_train = keras.utils.np_utils.to_categorical(y_train)\n",
        "#y_test = keras.utils.np_utils.to_categorical(y_test)\n",
        "#y_train = y_train.astype(int)\n",
        "#y_test = y_test.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9rZc0QnU-6S",
        "colab_type": "text"
      },
      "source": [
        "*Normalizing the images around a mean offset of 0 to put them into the model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_LK1T_xTEqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = (x_train/127.5)-1\n",
        "x_test = (x_test/127.5) -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa741OtpVBa7",
        "colab_type": "text"
      },
      "source": [
        "*Printing the training labels to make sure they have not been changed by the one hot encoding vectorization.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_IfB0qzTGYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (y_train[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXn89QJSVGVb",
        "colab_type": "text"
      },
      "source": [
        "*Checking the shape of the data. In this case, the labels increased a dimension from 1 to 2 because we have split the labels into two discrete categories, rather than just 0's and 1's*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trj_p8mJTJrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRAKLa4lVJBN",
        "colab_type": "text"
      },
      "source": [
        "*Importing the libararies needed to create the CNN architecture*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVY4OTugTNcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import save_model\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from IPython.display import Image\n",
        "from keras.optimizers import Adam\n",
        "#import tensorflow \n",
        "#import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrEys2ZsVMR9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac_ZZmGJTOOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"def myNet():\n",
        "    model = tf.keras.Sequential()\n",
        "    #model.add(Lambda(lambda x: x-0.5,input_shape = IMAGE_SHAPE))\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D(16,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))\n",
        "    #model.add(Conv2D(16,kernel_size=(3,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.50))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16,kernel_size=(3,3),activation='relu'))\n",
        "    #model.add(Conv2D(16,kernel_size=(3,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.50))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "    \n",
        "model = myNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Veh2o_VSq2",
        "colab_type": "text"
      },
      "source": [
        "*Specifiying how many classes there are, setting the basis of our model as MobileNetV2 (which is trained on imageNet, does not have the last classifcation layer, and with images of size 224x224x3). This allows our model to be based of an already trained ML model. A sequential model is created, with ResNet50 as the base. A flatten() is added so the images are in the right dimension for the softmax function. This last layer allows us to \"predict\" what class the image is labelled as based on the probability of the softmax function*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BllPXinMTRoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (224, 224, 3)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(2, activation = \"softmax\")\n",
        "    \n",
        "model = tf.keras.Sequential([\n",
        "  base_model\n",
        "])\n",
        "\n",
        "model.add(global_average_layer)\n",
        "model.add(prediction_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z9QYHNIVTnx",
        "colab_type": "text"
      },
      "source": [
        "Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLOJqMhdTT-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_learning_rate = 0.01 #0.003 , 0.001. 0.0003\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQDNZmC-VYy8",
        "colab_type": "text"
      },
      "source": [
        "*Printing the model to see what the model actually looks like*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPp7ULRNTZbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R29um3mVVb1V",
        "colab_type": "text"
      },
      "source": [
        "*Training the model with 10 epochs at 32 images per batch. This means that the model will run through all the data 10 times in segments of 32 images at a time, with x_train being the training set and y_test being the validation set.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFF1I6A4TbP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 10\n",
        "batch_for_training = 32\n",
        "\n",
        "\n",
        "callbacks_list = None\n",
        "history_one = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
        "      epochs=initial_epochs, batch_size=batch_for_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8JCebfrVhXg",
        "colab_type": "text"
      },
      "source": [
        "*Showing a graph of the training loss and the validation loss on a loss vs epoch graph*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzuug8GNTdQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history_one.history['loss'])\n",
        "plt.plot(history_one.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training loss','validation loss'],loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVck8SSuVql4",
        "colab_type": "text"
      },
      "source": [
        "*Saving the model then coverting the Tensorflow Model just trained into a Tensorflow Lite Model. This allows the model to be run on mobile devices.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M0r9iChTfQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_file = '/content/gdrive/My Drive/deer_model_new.h5'\n",
        "tf.keras.models.save_model(model, keras_file)\n",
        "\n",
        "# Convert to TensorFlow Lite model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
        "tflite_model = converter.convert()\n",
        "open(\"/content/gdrive/My Drive/converted_model_nonMobileNet.tflite\", \"wb\").write(tflite_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuHip3CVVtSe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   Add learning rate decay -> slows down learning rate over time going over epochs (not too big of a deal bc Adam optimizer already does this)\n",
        "*   Image amplification -> twists/rotate image for more training data,definitely look into soon to amplify amount of data\n",
        "*   Generator - from Chimpface, yield, function as an active list -> depends on how much RAM we have... genertor uses virtual arrays in batches to loop through large data sets. Probably more of a longer term solution when we have big data sets.\n",
        "*   Add learning rate decay -> slows down learning rate over time going voer epochs (not too big of a deal bc Adam optimizer already does this)\n",
        "*   Wild me data boxing -> currently using Labelbox, keep going\n",
        "*  Semantic segmentation architectures if boxing-facial recognitionrecognizing a face in an image -> waaayyyyy long term; rather than boxing an image, it outlines the image to count things (ask Chad to show the 'weird luke skywalker fire hydrant' video)\n",
        "\n",
        "\n"
      ]
    }
  ]
}