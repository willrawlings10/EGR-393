# -*- coding: utf-8 -*-
"""Make&Break DeerFinal_github.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kBh22XCEqC4vdCdUnUvRF5iisZPVIEA0

Original file is located at
    https://colab.research.google.com/drive/1TwghekMd1aRlIW1PwHA-qdFinfLBdiJA
**TensorFlow Code for Consevation X Labs Next-Generation Camera Trap** 
*   **Author**: Henrik Cox 
*  **Date Last Modified**:  August 15, 2019

Things attempted in this Make & Break:
Incorporate TensorBoard
Improve accuracy, reduce loss by tweaking hyperparameters

*Import the needed tensorflow and python libraries needed for data modification*
"""

from __future__ import absolute_import, division, print_function, unicode_literals

!pip install tensorflow==1.14.0rc1

#!pip install keras==2.2.4
import tensorflow as tf

import cv2
import PIL
import imageio
import os
import glob
import csv
import math
from pathlib import Path
import numpy as np
from skimage import io
from skimage import transform
from skimage import draw
from skimage import exposure
import matplotlib.pyplot as plt
import pickle
import requests
import tarfile
import dlib
import sys
from PIL import Image
from PIL.ExifTags import TAGS
!pip install -q tf-nightly
from sklearn.model_selection import train_test_split

import tarfile
import keras
import errno
import urllib
try:
    from imageio import imsave
except:
    from scipy.misc import imsave

  
import sys
import urllib.request
from urllib.request import urlretrieve
from csv import reader
import os.path
from PIL import Image
import requests
from io import BytesIO
from skimage import io
import matplotlib.image as mpimg
from scipy import ndimage, misc
import h5py
from IPython.display import display
from IPython.display import Image as _Imgdis
from PIL import Image
from scipy import ndimage

"""*Import the Google Drive Authorization needed to access the data folders*"""

from google.colab import drive
drive.mount('/content/gdrive')
!pip install -U -q PyDrive ## you will have install for every colab session
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

"""*Move into My Drive, where my image folders are stored*"""

cd '/content/gdrive/My Drive/CXL_Internship'

"""*Create the paths to the directories of the images, which are stored in their own folders in My Drive*"""

deer_train_path= '/content/gdrive/My Drive/CXL_Internship/Deer_Dataset/deer_train/'
notDeer_train_path = '/content/gdrive/My Drive/CXL_Internship/Deer_Dataset/notDeer_train/'

"""Download ngrok, required to visualise data using TensorBoard"""

!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip
!unzip ngrok-stable-linux-amd64.zip

"""Start TensorBoard in the background"""

LOG_DIR = './log'
get_ipython().system_raw(
    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'
    .format(LOG_DIR)
)

"""Tensorboard log path is assumed to be ".log" where Keras will log files

Run ngrok to tunnel TensorBoard port 6006 to outside world (runs in background)
"""

get_ipython().system_raw('./ngrok http 6006 &')

"""Get public URL to access Colab TensorBoard's web page"""

! curl -s http://localhost:4040/api/tunnels | python3 -c \
    "import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])"

"""@param: path_in - *The path to the folder of images*
@param: arrayName *An array to store the images*
Every file (or image) in the folder is read in RGB format, as BGR is the default for openCV
The image is the resized to (224,224), which is the height and width ised by most pre-trained models
The image is then appended to an array
The if statement is included because one of the images in the not deer training folder, at index 465, was not working and this bypassed that image 
@return: ArrayName *The same images now populated with image data*
"""

def imageAdder(path_in, arrayName):
   
    path = path_in
    i=0
    for image_path in os.listdir(path):
        if i==465 and path_in is notDeer_train_path:
            i=i+1
        else:    
            input_path = os.path.join(path, image_path)
            image = cv2.imread(input_path)
            image2 =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            #image = (image/127.5) - 1
            img = cv2.resize(image2,(224,224)) #crop rather than resize -keeps aspect ratio
            arrayName.append(img)
            print(image_path)
            i = i+1
    return arrayName

"""*Instantiating the arrays that will hold the training and testing images for deer and not deer*"""

deer_train = []
nDeer_train =[]

"""*Populating the previously instantiated arrays with image data from the folders*"""

deer_train = imageAdder(deer_train_path, deer_train)

nDeer_train = imageAdder(notDeer_train_path, nDeer_train)

#WHat does this cell do? Do we need it?
k= 0
for i in deer_train:
  shape = nDeer_train[0].shape
  if i.shape != shape:
    print(k)
  k=k+1

"""*Converting the arrays from lists to NumPy arrays, which allows for multi-dimensionality and is how the data will be fed into the model*"""

deer_train = np.asarray(deer_train)
nDeer_train =np.asarray(nDeer_train)

"""*Seeing the shape of the arrays holding the data*"""

print(deer_train.shape) 
print(nDeer_train.shape)

"""*Checking to see what a random index image looks like. This is the test to see if the images were imported correctly*"""

plt.imshow(deer_train[578])

"""*Creating the label arrays for the images. Assigning 1 to indicate a deer and 0 to indicate a not deer. Using np.ones or np.zeros created a numpy array of 1's or 0's, which have their length determined by the length of the corresponding image arrays. The prints after the assignments are used to test whether the labels were generated correctly.*"""

trainLabelsDeer = np.ones(len(deer_train))
print(len(trainLabelsDeer))

trainLabelsNotDeer = np.zeros(len(nDeer_train))
print(len(trainLabelsNotDeer))

"""*This adds the training labels together and the testing labels together in one array. The arrays are in order, so the first half are deer images and the second half are not deer images.*"""

x_total = np.concatenate((deer_train,nDeer_train))
y_total = np.concatenate((trainLabelsDeer, trainLabelsNotDeer))
y_total = keras.utils.np_utils.to_categorical(y_total)
y_total = y_total.astype(int)

"""*Printing the length of the training images, testing images, training labels and testing labels arrays to make sure the addition was successful*"""

print(len(x_total))
y_total = y_total.astype(int)
print(y_total)

"""*Printing the shape to make sure the images were all standardized (224x224x3) and that the number of samples is the number added as well*"""

print(x_total.shape)
print(y_total.shape)

x_train, x_test, y_train, y_test = train_test_split(x_total, y_total,test_size=0.2)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

"""*  @param: data - *Array containing images*
*  @param: labels *Array containing labels *
Shuffles both the data and the labels together so the data and labels do not become separated while the shuffle occurs.
The method takes a random state and shuffles the data according to that state, saves that state for the labels array and shuffles that array according to the same state.
*Shuffling of the training images and labels together as well as the testing images and labels together*
* **Commented Out**
* *Turning the labels into categories rather than just numbers. Use when using binary or categorical cross-entropy, not sparse categorical cross-entropy*
* However, I found that it is more accurate with sparse categorical cross-entropy
"""

#Do we need?

#y_train = keras.utils.np_utils.to_categorical(y_train)
#y_test = keras.utils.np_utils.to_categorical(y_test)
#y_train = y_train.astype(int)
#y_test = y_test.astype(int)

"""*Normalizing the images around a mean offset of 0 to put them into the model*"""

x_train = (x_train/127.5)-1
x_test = (x_test/127.5) -1

"""*Printing the training labels to make sure they have not been changed by the one hot encoding vectorization.*"""

print (y_train[:10])

"""*Checking the shape of the data. In this case, the labels increased a dimension from 1 to 2 because we have split the labels into two discrete categories, rather than just 0's and 1's*"""

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

"""*Importing the libararies needed to create the CNN architecture*"""

import keras
from keras.layers import *
from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
from keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.models import save_model
from keras.models import load_model
from tensorflow.keras import backend as K
from keras.layers.core import Dense, Activation
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.models import Model
from keras.applications import imagenet_utils
from keras.layers import Dense,GlobalAveragePooling2D
from keras.applications.mobilenet import preprocess_input
from IPython.display import Image
from keras.optimizers import Adam
import tensorflow 
import tensorflow_hub as hub

IMG_SHAPE = (224, 224, 3)

base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')

base_model.trainable = False

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
prediction_layer = tf.keras.layers.Dense(2, activation = "softmax")

model = tf.keras.Sequential([
  base_model
])

model.add(global_average_layer)
model.add(prediction_layer)

#Originally comented out. Uncomment to test for improvements
#now uncommented, let's see how it goes
#Nope, looks like it dropped accuracy...commenting out again
"""
def myNet():
    model = tf.keras.Sequential()
    #model.add(Lambda(lambda x: x-0.5,input_shape = IMAGE_SHAPE))
    
    model.add(tf.keras.layers.Conv2D(16,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))
    #model.add(Conv2D(16,kernel_size=(3,3),activation='relu'))
    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))
    model.add(tf.keras.layers.Dropout(0.50))
    model.add(tf.keras.layers.Conv2D(16,kernel_size=(3,3),activation='relu'))
    #model.add(Conv2D(16,kernel_size=(3,3),activation='relu'))
    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))
    model.add(tf.keras.layers.Dropout(0.50))
    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(128, activation='relu'))
    model.add(tf.keras.layers.Dense(2, activation='softmax'))
    return model
    
model = myNet()
"""

"""*Specifiying how many classes there are, setting the basis of our model as MobileNetV2 (which is trained on imageNet, does not have the last classifcation layer, and with images of size 224x224x3). This allows our model to be based of an already trained ML model. A sequential model is created, with ResNet50 as the base. A flatten() is added so the images are in the right dimension for the softmax function. This last layer allows us to "predict" what class the image is labelled as based on the probability of the softmax function*
y*

**Commented Out**
*Importing MobileNet to see how  well it could identify the images. It performs very poorly, thus we must retrain the model.*
from keras.preprocessing import image
from keras.applications import imagenet_utils, mobilenet
img_array = np.expand_dims(deer_train[20], axis=0)
pImg = mobilenet.preprocess_input(img_array)
mobilenet = mobilenet.MobileNet()
prediction = mobilenet.predict(pImg)
results = imagenet_utils.decode_predictions(prediction)
print(results)
plt.imshow(deer_train[20])
*The model is compiled with a binary_crossentropy loss, adam as the optimizer and the metrics as accuracy*
"""

#Compile

base_learning_rate = 0.01 #0.003 , 0.001. 0.0003
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

"""*Printing the model to see what the model actually looks like*"""

model.summary()

"""*Training the model with 10 epochs at 32 images per batch. This means that the model will run through all the data 10 times in segments of 32 images at a time, with x_train being the training set and y_test being the validation set.*"""

initial_epochs = 2 #5, should be 5 but for time aving purposes when testing code function... --> up to 10, later 20
batch_for_training = 32

callbacks_list = None
history_one = model.fit(x_train, y_train, validation_data=(x_test, y_test), 
      epochs=initial_epochs, batch_size=batch_for_training)

"""*Showing a graph of the training loss and the validation loss on a loss vs epoch graph*"""

plt.plot(history_one.history['loss'])
plt.plot(history_one.history['val_loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['training loss','validation loss'],loc='upper right')
plt.show()

"""*Saving the model then coverting the Tensorflow Model just trained into a Tensorflow Lite Model. This allows the model to be run on mobile devices.*"""

keras_file = '/content/gdrive/My Drive/CXL_Internship/models/cv2_224x224/deer_model_new.h5'
tf.keras.models.save_model(model, keras_file)

!pip install -U "tensorflow==1.14"

# Convert to TensorFlow Lite model.
converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)
tflite_model = converter.convert()
open("/content/gdrive/My Drive/CXL_Internship/models/bad/converted_model_nonMobileNet.tflite", "wb").write(tflite_model)

"""_______________________________
Everything below this line is extra from the colab code and not in the Github. Let's see how it runs
_______________________________
"""

base_model.trainable = True
fine_tune_at = 100
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable =  False

#commented out becuase there's a ValueError
#rest of the code below seems to run fine when this cell is commented out. Do we need it then?
#having a go at umcommenting right now - 08/19

base_learning_rate = 0.01 #0.003 , 0.001. 0.0003
model.compile(loss='binary_crossentropy',
              optimizer = 'adam',
              metrics=['accuracy'])

#did this help the error??
"""
from keras import backend as K

K.clear_session()
"""

fine_tune_epochs = 2 #change back to 10
total_epochs =  initial_epochs + fine_tune_epochs
history_fine = model.fit(x_train, y_train, validation_data=(x_test, y_test), 
      epochs=fine_tune_epochs, batch_size=batch_for_training)

keras_file = '/content/gdrive/My Drive/CXL_Internship/models/skimage_224x224/deer_model_skimage.h5'
tf.keras.models.save_model(model, keras_file)

converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)

"""*   Add learning rate decay
*  Image amplification
*  Generator - from Chimpface, yield, function as an active list
*  Wild me data boxing
*Semantic segmentation architectures if boxing-facial recognitionrecognizing a face in an image
"""